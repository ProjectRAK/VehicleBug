{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG19_noaug.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "smBjgu_cfn9L",
        "colab_type": "code",
        "outputId": "0a4f3821-c9dd-4452-f89f-79bf1e1022f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import backend as K\n",
        "from keras import Model\n",
        "from keras import utils as np_utils\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense,Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from keras.layers import Softmax, Dropout,Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bpTDmRDq8oog",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YBq87-5t8rtv",
        "colab_type": "code",
        "outputId": "68dddd31-b0fe-4f89-a68e-9b23610bf4ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fnRVnbEJ7lMB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSE_sUKA7lMI",
        "colab_type": "code",
        "outputId": "1e8a13b2-8e68-41b7-f80a-fa4bce712335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/damage_dataset/train',  # this is the target directory\n",
        "        target_size=(256, 256),  # all images will be resized to 256x256\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # \n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/content/drive/My Drive/damage_dataset/valid',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1860 images belonging to 8 classes.\n",
            "Found 396 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWkPz-TV7lMV",
        "colab_type": "code",
        "outputId": "7d084bed-59c4-413c-d46b-fd9f30eb37d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "epochs = 50\n",
        "\n",
        "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (256,256, 3))\n",
        "\n",
        "\n",
        "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
        "for layer in model.layers[:5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Adding custom Layers \n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(8, activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\",\n",
        "                    optimizer = optimizers.SGD(lr=0.0001,momentum=0.9),\n",
        "                    metrics=[\"accuracy\"] )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRm8YPmu7lMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the model according to the conditions  \n",
        "checkpoint = ModelCheckpoint(\"vgg19_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True,\n",
        "                             save_weights_only=True, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BgjBVJ9v4od",
        "colab_type": "code",
        "outputId": "e3498e67-9e6e-402a-c4e9-f72dd9895350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 19,911,808\n",
            "Non-trainable params: 112,576\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ntKquW-C7lMi",
        "colab_type": "code",
        "outputId": "1252940c-4d96-4de5-e399-abb60ac7a9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2172
        }
      },
      "cell_type": "code",
      "source": [
        "# Train the model \n",
        "history = model_final.fit_generator(\n",
        "train_generator,\n",
        "epochs = epochs,\n",
        "steps_per_epoch = 60 ,\n",
        "validation_data = validation_generator,\n",
        "validation_steps = 16,\n",
        "callbacks = [checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "60/60 [==============================] - 894s 15s/step - loss: 1.6022 - acc: 0.4880 - val_loss: 1.2589 - val_acc: 0.5772\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.57724, saving model to vgg19_weights.h5\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 1.2230 - acc: 0.5771 - val_loss: 0.9057 - val_acc: 0.7500\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.57724 to 0.75000, saving model to vgg19_weights.h5\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.9291 - acc: 0.6896 - val_loss: 0.7015 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.75000 to 0.78659, saving model to vgg19_weights.h5\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.7231 - acc: 0.7568 - val_loss: 0.5665 - val_acc: 0.8369\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.78659 to 0.83686, saving model to vgg19_weights.h5\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.5987 - acc: 0.8052 - val_loss: 0.5844 - val_acc: 0.8252\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.83686\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.4984 - acc: 0.8401 - val_loss: 0.4202 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.83686 to 0.87602, saving model to vgg19_weights.h5\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.3959 - acc: 0.8791 - val_loss: 0.4143 - val_acc: 0.8659\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.87602\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.3320 - acc: 0.8937 - val_loss: 0.3173 - val_acc: 0.9187\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.87602 to 0.91870, saving model to vgg19_weights.h5\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.2687 - acc: 0.9151 - val_loss: 0.3083 - val_acc: 0.9068\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.91870\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.2562 - acc: 0.9162 - val_loss: 0.3290 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.91870\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1850 - acc: 0.9349 - val_loss: 0.3513 - val_acc: 0.8984\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.91870\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1443 - acc: 0.9527 - val_loss: 0.3712 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.91870\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1523 - acc: 0.9531 - val_loss: 0.3036 - val_acc: 0.9216\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.91870 to 0.92161, saving model to vgg19_weights.h5\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1109 - acc: 0.9656 - val_loss: 0.3918 - val_acc: 0.8923\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.92161\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.0720 - acc: 0.9797 - val_loss: 0.3451 - val_acc: 0.9248\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.92161 to 0.92480, saving model to vgg19_weights.h5\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.0599 - acc: 0.9812 - val_loss: 0.3176 - val_acc: 0.9350\n",
            "\n",
            "Epoch 00016: val_acc improved from 0.92480 to 0.93496, saving model to vgg19_weights.h5\n",
            "Epoch 17/50\n",
            "37/60 [=================>............] - ETA: 22s - loss: 0.0588 - acc: 0.9831"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-da4e9a1bd89b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m callbacks = [checkpoint, early])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1kU31AvwsyO-",
        "colab_type": "code",
        "outputId": "68c0db83-527b-41bc-de02-2cfa36fdb1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_json = model_final.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H_5GW9caM4La",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Making Predictions**"
      ]
    },
    {
      "metadata": {
        "id": "dRp2Z7D8xgJ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "img = cv2.imread('/content/drive/My Drive/test/smash.jpeg', cv2.IMREAD_UNCHANGED)\n",
        "x = cv2.resize(img, (299, 299))\n",
        "y = x.reshape(-1, 299, 299, 3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fHbTRa_h8yRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model1 = load_model('/content/vgg19_299.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Cnfl4LhzchF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_prob = model1.predict(y) \n",
        "y_classes = y_prob.argmax(axis=-1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7s0gniALtceE",
        "colab_type": "code",
        "outputId": "86c31ef0-758b-4d41-b4f1-ee3968b9ecd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_prob"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "hwoMeqYCkppZ",
        "colab_type": "code",
        "outputId": "2a2b9a8b-5ce4-4c88-a39d-9274f831a50e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in y_classes]\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No damage']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-_Gb7c-UdPwt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jufazZDjcqji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}